# Section 4: Using the Object Storage

## 4.1 Creating application credentials

In this section you will create an [application
credential](https://access.redhat.com/documentation/zh-cn/red_hat_openstack_platform/14/html/users_and_identity_management_guide/application_credentials)
and download the autogenerated `clouds.yaml`. `clouds.yaml` contains all
required authentication information. Follow the images:

![Navigation](images/ac_screen1.png)

Don't use the input field secret. As you can see its input is not
hidden. OpenStack will generate a strong secret for you, if you leave it
blank. You should pick a sensible expiration date.

![Creation](images/ac_screen2.png)

Save the downloaded `clouds.yaml` under `~/.config/openstack/`. That
will allow the `OpenstackClient` to access it. You will also need the
`app-cred-openrc.sh` script finish the setup.

![Download](images/ac_screen3.png)

If the file was auto downloaded, you need to move it instead:

``` bash
mkdir -p ~/.config/openstack
mv ~/Downloads/clouds.yaml ~/.config/openstack/
source ~/Downloads/app-cred-openrc.sh
```

If you have `OpenstackClient` installed and `openstack subnet list` runs
without error, you are ready to proceed.

``` bash
openstack subnet list
```

## 4.2 Creating S3 credentials

The creation of credentials for the project related object storage can't
be done in the web interface. Therefore, we will use the openstack CLI
for that.

``` bash
openstack --os-identity-api-version 3 ec2 credentials create
```

This command will return you the newly generated key and secret. You
can, at any time, look up what S3 credentials are still valid for you
using

``` bash
openstack --os-identity-api-version 3 ec2 credentials list
```

We will now configure the S3 minio client:

``` bash
mc alias set ibworkshop https://openstack.cebitec.uni-bielefeld.de:8080/ <YOUR-ACCESS-KEY> <YOUR-SECRET-KEY>
```

## 4.3 Uploading data to the Object Storage

We will now use the minio client to upload some data. In the guacamole
SimpleVM instance, type:

``` bash
mkdir ~/data/fastq

mc cp sra/ftp.era.ebi.ac.uk/vol1/fastq/SRR398/008/SRR3984908/SRR3984908_1.fastq.gz ~/data/fastq/reads_1.fastq.gz
mc cp sra/ftp.era.ebi.ac.uk/vol1/fastq/SRR398/008/SRR3984908/SRR3984908_2.fastq.gz ~/data/fastq/reads_2.fastq.gz

cd ~/data/fastq
mc ls ibworkshop
```

This should show you your previously created bucket (container) name.
You can now upload data into it.

``` bash
mc cp *.fastq ibworkshop/YOUR_CONTAINER_NAME
mc ls ibworkshop/YOUR_CONTAINER_NAME
```

![](figures/minio_verify.png)

## 4.4 Additional Object Storage Operations

For more advanced work with the SRA mirror and metagenomic datasets
analysis, please refer to [Section
3.4](Part3.md#34-make-the-analysis-where-the-data-is-located) where we
covered working with the de.NBI Cloud SRA mirror in detail.

Here are some additional useful object storage operations:

1.  **Copy data between buckets:**

    ``` bash
    mc cp ibworkshop/YOUR_CONTAINER_NAME/file.txt ibworkshop/ANOTHER_CONTAINER/
    ```

2.  **Mirror entire directories:**

    ``` bash
    mc mirror ~/local_data ibworkshop/YOUR_CONTAINER_NAME/backup/
    ```

3.  **Set public access for sharing data:**

    ``` bash
    mc policy set download ibworkshop/YOUR_CONTAINER_NAME/public/
    ```

4.  **Monitor transfer progress:**

    ``` bash
    mc cp --json large_file.gz ibworkshop/YOUR_CONTAINER_NAME/ | jq .
    ```

## Advanced Data Transfer Methods

This section covers advanced data transfer techniques for moving data
efficiently between cloud instances, object storage containers, and
hybrid environments. These methods are particularly useful for
large-scale data processing workflows and collaborative research
projects.

## 4.5 Advanced Object Storage Operations

### 4.5.1 Cross-region data replication

**Use Case**: You're collaborating with researchers at different de.NBI
sites (Bielefeld, Heidelberg, Geissen, Berlin, etc.) and need to share
large metagenomic datasets. Cross-region replication ensures data
availability and reduces transfer times.

**How it works**: Data is automatically synchronized between different
de.NBI cloud regions, providing redundancy and faster access for
collaborators.

Advantages:

-   **Disaster recovery**: If one region is unavailable, data remains
    accessible

-   **Collaboration**: Multiple teams can work on the same datasets
    simultaneously

``` bash
# Configure multiple regions (for example)
mc alias set UniBi https://openstack.cebitec.uni-bielefeld.de:8080/ <ACCESS-KEY> <SECRET-KEY>
mc alias set UniHe https://denbi-cloud.bioquant.uni-heidelberg.de:8080/ <ACCESS-KEY> <SECRET-KEY>

# Replicate data between regions
mc mirror ibworkshop/YOUR_CONTAINER_NAME UniHe/BACKUP_CONTAINER/
```

### 4.5.2 Batch operations with minio client

**Use Case**: You have hundreds of sequencing files from different
experiments that need to be organized and uploaded to object storage.
Manual upload would take hours and be error-prone.

**How it works**: Minio client can process multiple files simultaneously
using wildcards and patterns, with built-in progress monitoring and
error handling.

**Advantages:**

-   **Time savings**: Upload hundreds of files in one command instead of
    individual uploads

-   **Error reduction**: Automated pattern matching reduces human errors

-   **Progress tracking**: Monitor large transfers with real-time
    progress bars

``` bash
# Upload multiple file types with wildcards
mc cp ~/data/*.{fastq,fna,fa} ibworkshop/YOUR_CONTAINER_NAME/raw_data/

# Download files matching specific patterns
mc find ibworkshop/YOUR_CONTAINER_NAME --name "*.fastq.gz" --exec "mc cp {} ~/downloads/"

# Sync directories with progress monitoring
mc mirror --progress ~/local_data ibworkshop/YOUR_CONTAINER_NAME/synced_data/
```

## 4.6 Advanced SSH-based Transfers

### 4.6.1 Using rsync for efficient transfers

**Use Case**: You're regularly updating large datasets (like reference
genomes or annotation files) or need to make regular daily or weekly
backups.

**How it works**: Rsync compares file timestamps and sizes, transferring
only the differences between source and destination. This is especially
efficient for incremental backups and dataset updates.

**Advantages**:

-   **Time efficiency**: Updates take minutes instead of hours for large
    datasets

-   **Resume capability**: Interrupted transfers can be resumed from
    where they left off

-   **Compression**: Built-in compression reduces transfer size and time

``` bash
# Sync directories between instances
rsync -avz -e "ssh -p YOUR_PORT" ubuntu@YOUR_VM_IP:/mnt/volume/data/ ~/local_backup/

# Transfer with compression and progress
rsync -avzP -e "ssh -p YOUR_PORT" ~/large_dataset/ ubuntu@YOUR_VM_IP:/mnt/volume/

# Exclude certain file types.
rsync -avz --exclude="*.tmp" --exclude="*.log" -e "ssh -p YOUR_PORT" ~/data/ ubuntu@YOUR_VM_IP:/mnt/volume/
```

### 4.6.2 Parallel transfers with GNU parallel

**Use Case**: You have thousands of sequencing files that need to be
transferred to the cloud, and sequential transfer would take days.

**How it works**: GNU parallel manages multiple transfer processes
simultaneously, utilizing available bandwidth and CPU cores efficiently.

**Advantages**:

-   **Speed**: Transfer multiple files simultaneously, utilizing more
    resources, and improving transfer throughput.

-   **Monitoring**: Track progress of all transfers simultaneously

``` bash
# Create a list of files to transfer
find ~/data -name "*.fastq" > files_to_transfer.txt

# Transfer files in parallel (4 at a time)
parallel -j 4 -a files_to_transfer.txt scp -i ~/.ssh/*.pem -P YOUR_PORT {} ubuntu@YOUR_VM_IP:/mnt/volume/
```

### 4.7 Transfer speed optimization

**Use Case**: You're transferring terabytes of sequencing data and need
to maximize transfer speeds to meet project deadlines or minimize cloud
costs.

**How it works**: Various techniques can be combined to optimize
transfer performance, including parallel connections, compression, and
optimized encryption.

**Advantages**:

-   **Time savings**: Reduce transfer times by 50-80% through
    optimization

-   **Cost reduction**: Faster transfers mean less VM time and lower
    costs

-   **Bandwidth utilization**: Make full use of available network
    capacity

-   **Scalability**: Techniques work for datasets of any size

``` bash
# Use multiple connections for faster transfers
mc cp --concurrent 4 large_file.gz ibworkshop/YOUR_CONTAINER_NAME/

# Compress data during transfer
rsync -avz --compress-level=9 -e "ssh -p YOUR_PORT" ~/data/ ubuntu@YOUR_VM_IP:/mnt/volume/
```

### 4.8 Resume interrupted transfers

**Use Case**: You're transferring large genomic datasets and the
connection is interrupted (network issues, VM restarts, etc.). Without
resume capability, you'd have to start over from the beginning.

**How it works**: Transfer tools can resume from where they left off,
using partial files and transfer logs to avoid re-transferring already
completed portions.

**Advantages**:

-   **Time savings**: Resume from interruption point instead of starting
    over

-   **Bandwidth efficiency**: Don't waste bandwidth on already
    transferred data

-   **Reliability**: Handle network interruptions gracefully

-   **Cost savings**: Avoid repeated transfer costs for large datasets

``` bash
# Resume interrupted rsync transfers
rsync -avz --partial --progress -e "ssh -p YOUR_PORT" ~/large_dataset/ ubuntu@YOUR_VM_IP:/mnt/volume/

# Resume interrupted minio transfers
mc cp --continue ibworkshop/YOUR_CONTAINER_NAME/large_file.gz ~/
```

Back to [Section 3](Part3.md)
